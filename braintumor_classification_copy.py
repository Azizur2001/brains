# -*- coding: utf-8 -*-
"""BrainTumor_classification_copy.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IzRmjEpjen49piZGdbVfDdlEcOnsr2A_
"""

import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

import subprocess

subprocess.run(["kaggle", "datasets", "download", "-d", "masoudnickparvar/brain-tumor-mri-dataset", "--unzip"])

def get_class_paths(path):
    classes = []
    class_paths = []

    for label in os.listdir(path):
      label_path = os.path.join(path, label)

      if os.path.isdir(label_path):
        for image in os.listdir(label_path):
          image_path = os.path.join(label_path, image)
          classes.append(label)
          class_paths.append(image_path)

    df = pd.DataFrame({
        'Class Path': class_paths,
        'Class': classes
    })

    return df

tr_df = get_class_paths("/content/Training")

tr_df

ts_df = get_class_paths("/content/Testing")

ts_df

plt.figure(figsize=(15,7))
ax = sns.countplot(data=tr_df, x=tr_df['Class'])

plt.figure(figsize=(15,7))
ax = sns.countplot(data=ts_df, x=ts_df['Class'])

from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, Flatten
from tensorflow.keras.optimizers import Adamax
from tensorflow.keras.metrics import Precision, Recall
from tensorflow.keras.preprocessing.image import ImageDataGenerator

valid_df, ts_df = train_test_split(ts_df, train_size=0.5, stratify=ts_df['Class'])

valid_df

ts_df

batch_size = 32

img_size = (299, 299)

image_generator = ImageDataGenerator(rescale=1/255, brightness_range=(0.8, 1.2))

ts_gen = ImageDataGenerator(rescale=1/255)

tr_gen = image_generator.flow_from_dataframe(tr_df, x_col='Class Path',
                                             y_col='Class',
                                             batch_size=batch_size,
                                             target_size=img_size)


valid_gen = image_generator.flow_from_dataframe(valid_df, x_col='Class Path',
                                             y_col='Class',
                                             batch_size=batch_size,
                                             target_size=img_size)


ts_gen = ts_gen.flow_from_dataframe(ts_df, x_col='Class Path',
                                             y_col='Class',
                                             batch_size=16,
                                             target_size=img_size, shuffle=False)

plt.figure(figsize=(20, 20))
for i in range(16):
    plt.subplot(4, 4, i+1)
    batch = next(tr_gen)
    image = batch[0][0]
    label = batch[1][0]
    plt.imshow(image)

    # Get the class index
    class_index = np.argmax(label)

    # Get the list of class names and class indices
    class_names = list(tr_gen.class_indices.keys())
    class_indices = list(tr_gen.class_indices.values())

    # Find the index of the class_index in the list of indices
    index_position = class_indices.index(class_index)

    # Get the class name using the index position
    class_name = class_names[index_position]

    plt.title(f"Class: {class_name}")
    plt.axis('off')
plt.tight_layout()
plt.show()

img_shape = (299, 299, 3)

base_model = tf.keras.applications.Xception(include_top=False,
                                            weights="imagenet",
                                            input_shape=img_shape,
                                            pooling='max')

model = Sequential([
    base_model,
    Flatten(),
    Dropout(rate=0.3),
    Dense(128, activation='relu'),
    Dropout(rate=0.25),
    Dense(4, activation='softmax')
])

model.compile(Adamax(learning_rate=0.001),
              loss='categorical_crossentropy',
              metrics=['accuracy',
              Precision(),
              Recall()])

hist = model.fit(tr_gen, epochs=5, validation_data=valid_gen)

# Get training and validation metrics from history
metrics = ['accuracy', 'loss', 'precision', 'recall']
tr_metrics = {m: hist.history[m] for m in metrics}
val_metrics = {m: hist.history[f'val_{m}'] for m in metrics}

# Find best epochs and values
best_epochs = {}
best_values = {}
for m in metrics:
    if m == 'loss':
        idx = np.argmin(val_metrics[m])
    else:
        idx = np.argmax(val_metrics[m])
    best_epochs[m] = idx + 1
    best_values[m] = val_metrics[m][idx]

# Plot metrics
plt.figure(figsize=(20, 12))
plt.style.use('fivethirtyeight')

for i, metric in enumerate(metrics, 1):
    plt.subplot(2, 2, i)
    epochs = range(1, len(tr_metrics[metric]) + 1)

    plt.plot(epochs, tr_metrics[metric], 'r', label=f'Training {metric}')
    plt.plot(epochs, val_metrics[metric], 'g', label=f'Validation {metric}')
    plt.scatter(best_epochs[metric], best_values[metric], s=150, c='blue',
                label=f'Best epoch = {best_epochs[metric]}')

    plt.title(f'Training and Validation {metric.title()}')
    plt.xlabel('Epochs')
    plt.ylabel(metric.title())
    plt.legend()
    plt.grid(True)

plt.suptitle('Model Training Metrics Over Epochs', fontsize=16)
plt.show()

train_score = model.evaluate(tr_gen, verbose=1)
valid_score = model.evaluate(valid_gen, verbose=1)
test_score = model.evaluate(ts_gen, verbose=1)

print(f"Train Accuracy: {train_score[1]*100:.2f}%")
print(f"Train Loss: {train_score[0]:.4f}")

print(f"\n\nValidation Accuracy: {valid_score[1]*100:.2f}%")
print(f"Validation Loss: {valid_score[0]:.4f}")

print(f"\n\nTest Accuracy: {test_score[1]*100:.2f}%")
print(f"Test Loss: {test_score[0]:.4f}")

preds = model.predict(ts_gen)
y_pred = np.argmax(preds, axis=1)

class_dict = {
    0: 'glioma',
    1: 'meningioma',
    2: 'no_tumor',
    3: 'pituitary'
}

# Then create and display the confusion matrix
cm = confusion_matrix(ts_gen.classes, y_pred)
labels = list(class_dict.keys())
plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix')
plt.show()

from PIL import Image

def predict(img_path: str) -> None:
    # Get class labels
    labels = list(class_dict.keys())

    # Create figure
    plt.figure(figsize=(6, 8))

    # Load and preprocess image
    img = Image.open(img_path)
    resized_img = img.resize((299, 299))
    img_array = np.asarray(resized_img)
    img_array = np.expand_dims(img_array, axis=0) / 255.0

    # Get model predictions
    predictions = model.predict(img_array)
    probabilities = list(predictions[0])

    # Get predicted class
    predicted_class_idx = np.argmax(probabilities)
    predicted_class = class_dict[predicted_class_idx]

    # Plot original image
    plt.subplot(2, 1, 1)
    plt.imshow(resized_img)
    plt.title(f"Input MRI Image\nPredicted: {predicted_class}")

    # Plot prediction probabilities
    plt.subplot(2, 1, 2)
    bars = plt.barh(labels, probabilities)
    plt.xlabel("Probability", fontsize=15)
    plt.title("Class Probabilities")

    # Add probability labels to bars
    ax = plt.gca()
    ax.bar_label(bars, fmt="%.2f")

    plt.tight_layout()
    plt.show()

    print(f"\nPredicted tumor type: {predicted_class}")

predict("/content/Testing/meningioma/Te-meTr_0000.jpg")

predict("/content/Testing/meningioma/Te-meTr_0005.jpg")

predict("/content/Testing/glioma/Te-glTr_0000.jpg")

model.save_weights("xception_model.weights.h5")

from tensorflow.keras.layers import Conv2D, MaxPooling2D
from tensorflow.keras import regularizer

batch_size = 16

img_size = (224, 224)

image_generator = ImageDataGenerator(rescale=1/255, brightness_range=(0.8, 1.2))

ts_gen = ImageDataGenerator(rescale=1/255)


tr_gen = image_generator.flow_from_dataframe(tr_df, x_col='Class Path',
                                             y_col='Class',
                                             batch_size=batch_size,
                                             target_size=img_size)


valid_gen = image_generator.flow_from_dataframe(valid_df, x_col='Class Path',
                                             y_col='Class',
                                             batch_size=batch_size,
                                             target_size=img_size)


ts_gen = ts_gen.flow_from_dataframe(ts_df, x_col='Class Path',
                                             y_col='Class',
                                             batch_size=16,
                                             target_size=img_size, shuffle=False)

# Create a Sequential model
cnn_model = Sequential()

# Convolutional layers
cnn_model.add(Conv2D(512, (3, 3), padding='same', input_shape=(224,224,3), activation='relu'))
cnn_model.add(MaxPooling2D(pool_size=(2, 2)))

cnn_model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))
cnn_model.add(MaxPooling2D(pool_size=(2, 2)))
cnn_model.add(Dropout(0.25))

cnn_model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))
cnn_model.add(MaxPooling2D(pool_size=(2, 2)))
cnn_model.add(Dropout(0.25))

cnn_model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))
cnn_model.add(MaxPooling2D(pool_size=(2, 2)))

# Flatten the output for fully connected layers
cnn_model.add(Flatten())

# Fully connected layers
cnn_model.add(Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.01)))
cnn_model.add(Dropout(0.35))

cnn_model.add(Dense(4, activation='softmax'))  # Output layer with 4 neurons for the 4 classes

# Compile the model
cnn_model.compile(Adamax(learning_rate = 0.001), loss='categorical_crossentropy', metrics=['accuracy', Precision(), Recall()])

# Display the model summary
cnn_model.summary()

history = cnn_model.fit(tr_gen, epochs=5, validation_data=valid_gen)

# Get training and validation metrics from history
metrics = ['accuracy', 'loss', 'precision', 'recall']
tr_metrics = {m: history.history[m] for m in metrics}
val_metrics = {m: history.history[f'val_{m}'] for m in metrics}

# Find best epochs and values
best_epochs = {}
best_values = {}
for m in metrics:
    if m == 'loss':
        idx = np.argmin(val_metrics[m])
    else:
        idx = np.argmax(val_metrics[m])
    best_epochs[m] = idx + 1
    best_values[m] = val_metrics[m][idx]

# Plot metrics
plt.figure(figsize=(20, 12))
plt.style.use('fivethirtyeight')

for i, metric in enumerate(metrics, 1):
    plt.subplot(2, 2, i)
    epochs = range(1, len(tr_metrics[metric]) + 1)

    plt.plot(epochs, tr_metrics[metric], 'r', label=f'Training {metric}')
    plt.plot(epochs, val_metrics[metric], 'g', label=f'Validation {metric}')
    plt.scatter(best_epochs[metric], best_values[metric], s=150, c='blue',
                label=f'Best epoch = {best_epochs[metric]}')

    plt.title(f'Training and Validation {metric.title()}')
    plt.xlabel('Epochs')
    plt.ylabel(metric.title())
    plt.legend()
    plt.grid(True)

plt.suptitle('Model Training Metrics Over Epochs', fontsize=16)
plt.show()

train_score = cnn_model.evaluate(tr_gen, verbose=1)
valid_score = cnn_model.evaluate(valid_gen, verbose=1)
test_score = cnn_model.evaluate(ts_gen, verbose=1)

print(f"Train Accuracy: {train_score[1]*100:.2f}%")
print(f"Train Loss: {train_score[0]:.4f}")

print(f"\n\nValidation Accuracy: {valid_score[1]*100:.2f}%")
print(f"Validation Loss: {valid_score[0]:.4f}")

print(f"\n\nTest Accuracy: {test_score[1]*100:.2f}%")
print(f"Test Loss: {test_score[0]:.4f}")

preds = cnn_model.predict(ts_gen)
y_pred = np.argmax(preds, axis=1)

class_dict = {
    0: 'glioma',
    1: 'meningioma',
    2: 'no_tumor',
    3: 'pituitary'
}

# Then create and display the confusion matrix
cm = confusion_matrix(ts_gen.classes, y_pred)
labels = list(class_dict.keys())
plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix')
plt.show()

clr = classification_report(ts_gen.classes, y_pred)
print(clr)

cnn_model.save("cnn_model.h5")

import subprocess

subprocess.run(["pip", "install", "streamlit", "pyngrok", "python-dotenv"])


from threading import Thread
from pyngrok import ngrok
from google.colab import userdata

ngrok_token = userdata.get('NGROK_AUTH_TOKEN')
ngrok.set_auth_token(ngrok_token)

def run_streamlit():
  os.system("streamlit run /content/app.py --server.port 8501")

# Commented out IPython magic to ensure Python compatibility.
# # %%writefile app.py
# 
# # import streamlit as st
# # import tensorflow as tf
# # from tensorflow.keras.models import load_model
# # from tensorflow.keras.preprocessing import image
# # import numpy as np
# # import plotly.graph_objects as go
# # import cv2
# # from tensorflow.keras.models import Sequential
# # from tensorflow.keras.layers import Dense, Dropout, Flatten
# # from tensorflow.keras.optimizers import Adamax
# # from tensorflow.keras.metrics import Precision, Recall
# # import google.generativeai as genai
# # from google.colab import userdata
# # import PIL.Image
# # import os
# # from google.colab import userdata
# # from dotenv import load_dotenv
# # load_dotenv()
# 
# 
# # genai.configure(api_key=os.getenv("GOOGLE_API_KEY"))
# 
# 
# # output_dir = 'saliency_maps'
# # os.makedirs(output_dir, exist_ok=True)
# 
# 
# # def generate_explanation(img_path, model_prediction, confidence):
# 
# #     prompt = f"""
# #     You are an expert neurologist interpreting a saliency map for a brain MRI scan, generated by a deep learning model trained to classify brain tumors into categories: glioma, meningioma, pituitary, or no tumor.
# 
# #     The model predicted the scan to be of class '{model_prediction}' with a confidence level of {confidence * 100}%.
# 
# #     Context for response:
# #     - Describe specific regions of the brain highlighted in light cyan where the model focused to arrive at this prediction.
# #       For example, reference specific lobes, sulci, or anatomical structures if they appear relevant.
# #     - Discuss how the highlighted regions correlate with typical tumor presentation of the predicted class. For instance,
# #       explain if the distribution, shape, or spread of these highlighted areas aligns with known patterns for {model_prediction}.
# #     - Provide insights into the reasoning process, considering the neural features that might influence the model's focus.
# #       For example, mention if it’s emphasizing regions of abnormal density, asymmetry, or unusual boundaries that are often seen in {model_prediction} cases.
# #     - Avoid generic statements, and aim to make each sentence contribute a unique insight into why the model likely made this prediction
# #       based on the observed highlights.
# #     - Maintain clarity and precision in describing the anatomical and functional relevance of the model’s focus points on the MRI scan.
# #     Please provide an expert-level explanation that helps the user understand the saliency map's findings and the model’s focus.
# #     """
# 
# #     img = PIL.Image.open(img_path)
# 
# #     model = genai.GenerativeModel(model_name="gemini-1.5-flash")
# #     response = model.generate_content([prompt, img])
# 
# #     return response.text
# 
# 
# # def generate_saliency_map(model, img_array, class_index, img_size):
# #     with tf.GradientTape() as tape:
# #         img_tensor = tf.convert_to_tensor(img_array)
# #         tape.watch(img_tensor)
# #         predictions = model(img_tensor)
# #         target_class = predictions[:, class_index]
# 
# #     gradients = tape.gradient(target_class, img_tensor)
# #     gradients = tf.math.abs(gradients)
# #     gradients = tf.reduce_max(gradients, axis=-1)
# #     gradients = gradients.numpy().squeeze()
# 
# #     # Resize gradients to match original image size
# #     gradients = cv2.resize(gradients, img_size)
# 
# #     # Create a circular mask for the brain area
# #     center = (gradients.shape[0] // 2, gradients.shape[1] // 2)
# #     radius = min(center[0], center[1]) - 10
# #     y, x = np.ogrid[:gradients.shape[0], :gradients.shape[1]]
# #     mask = (x - center[0])**2 + (y - center[1])**2 <= radius**2
# 
# #     # Apply mask to gradients
# #     gradients = gradients * mask
# 
# #     # Normalize only the brain area
# #     brain_gradients = gradients[mask]
# #     if brain_gradients.max() > brain_gradients.min():
# #         brain_gradients = (brain_gradients - brain_gradients.min()) / (brain_gradients.max() - brain_gradients.min())
# #     gradients[mask] = brain_gradients
# 
# #     # Apply a higher threshold
# #     threshold = np.percentile(gradients[mask], 80)
# #     gradients[gradients < threshold] = 0
# 
# #     # Apply more aggressive smoothing
# #     gradients = cv2.GaussianBlur(gradients, (11, 11), 0)
# 
# #     # Create a heatmap overlay with enhanced contrast
# #     heatmap = cv2.applyColorMap(np.uint8(255 * gradients), cv2.COLORMAP_JET)
# #     heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)
# 
# #     # Resize heatmap to match original image size
# #     heatmap = cv2.resize(heatmap, img_size)
# #     # Superimpose the heatmap on original image with increased opacity
# #     original_img = image.img_to_array(img)
# #     superimposed_img = heatmap * 0.7 + original_img * 0.3
# #     superimposed_img = superimposed_img.astype(np.uint8)
# 
# #     img_path = os.path.join(output_dir, uploaded_file.name)
# #     with open(img_path, "wb") as f:
# #         f.write(uploaded_file.getbuffer())
# 
# #     saliency_map_path = f'saliency_maps/{uploaded_file.name}'
# 
# #     # Save the saliency map
# #     cv2.imwrite(saliency_map_path, cv2.cvtColor(superimposed_img, cv2.COLOR_RGB2BGR))
# 
# #     return superimposed_img
# 
# 
# 
# 
# # def load_xception_model(model_path):
# #     img_shape=(299,299,3)
# #     base_model = tf.keras.applications.Xception(include_top=False, weights="imagenet",
# #                                                 input_shape=img_shape, pooling='max')
# 
# #     model = Sequential([
# #         base_model,
# #         Flatten(),
# #         Dropout(rate=0.3),
# #         Dense(128, activation='relu'),
# #         Dropout(rate=0.25),
# #         Dense(4, activation='softmax')
# #     ])
# 
# #     model.build((None,) + img_shape)
# 
# #     # Compile the model
# #     model.compile(Adamax(learning_rate=0.001),
# #                   loss='categorical_crossentropy',
# #                   metrics=['accuracy',
# #                            Precision(),
# #                            Recall()])
# 
# #     model.load_weights(model_path)
# 
# #     return model
# 
# 
# 
# # st.title("Brain Tumor Classification")
# 
# # st.write("Upload an image of a brain MRI to classify the tumor type.")
# 
# # uploaded_file = st.file_uploader("Choose an image...", type=["jpg", "jpeg", "png"])
# 
# # if uploaded_file is not None:
# #   selected_model = st.radio(
# #       "Select Model",
# #       ("Transfer Learning - Xception", "Custom CNN")
# #   )
# 
# #   if selected_model == "Transfer Learning - Xception":
# #     model = load_xception_model('/content/xception_model.weights.h5')
# #     img_size = (299, 299)
# #   else:
# #     model = load_model('/content/cnn_model.h5')
# #     img_size = (224, 224)
# 
# 
# 
# #   labels = ['Glioma', 'Meningioma', 'No tumor', 'Pituitary']
# #   img = image.load_img(uploaded_file, target_size=img_size)
# #   img_array = image.img_to_array(img)
# #   img_array = np.expand_dims(img_array, axis=0)
# #   img_array /= 255.0
# 
# #   prediction = model.predict(img_array)
# 
# #   class_index = np.argmax(prediction[0])
# #   result = labels[class_index]
# 
# #   st.write(f"Predicted Class: {result}")
# #   st.write("Predictions")
# #   for label, prob in zip(labels, prediction[0]):
# #     st.write(f"{label}: {prob:.4f}")
# 
# 
# 
# #   saliency_map = generate_saliency_map(model, img_array, class_index, img_size)
# 
# #   col1, col2 = st.columns(2)
# #   with col1:
# #     st.image(uploaded_file, caption='Uploaded Image', use_column_width = True)
# #   with col2:
# #     st.image(saliency_map, caption='Saliency Map', use_column_width=True)
# 
# 
# 
# 
# 
# #   st.write("## Classification Results")
# 
# #   result_container = st.container()
# #   result_container = st.container()
# #   result_container.markdown(
# #       f"""
# #       <div style="background-color: #000000; color: #ffffff; padding: 30px; border-radius: 15px;">
# #           <div style="display: flex; justify-content: space-between; align-items: center;">
# #               <div style="flex: 1; text-align: center;">
# #                   <h3 style="color: #ffffff; margin-bottom: 10px; font-size: 20px;">Prediction</h3>
# #                   <p style="font-size: 36px; font-weight: 800; color: #FF0000; margin: 0;">
# #                       {result}
# #                   </p>
# #               </div>
# #               <div style="width: 2px; height: 80px; background-color: #ffffff; margin: 0 20px;"></div>
# #               <div style="flex: 1; text-align: center;">
# #                   <h3 style="color: #ffffff; margin-bottom: 10px; font-size: 20px;">Confidence</h3>
# #                   <p style="font-size: 36px; font-weight: 800; color: #2196F3; margin: 0;">
# #                       {prediction[0][class_index]:.4%}
# #                   </p>
# #               </div>
# #           </div>
# #       </div>
# #       """,
# #       unsafe_allow_html=True
# #   )
# 
# #   # Prepare data for Plotly chart
# #   probabilities = prediction[0]
# #   sorted_indices = np.argsort(probabilities)[::-1]
# #   sorted_labels = [labels[i] for i in sorted_indices]
# #   sorted_probabilities = probabilities[sorted_indices]
# 
# #   # Create a Plotly bar chart
# #   fig = go.Figure(go.Bar(
# #   x=sorted_probabilities,
# #   y=sorted_labels,
# #   orientation='h',
# #   marker_color=['red' if label == result else 'blue' for label in sorted_labels]
# #   ))
# 
# #   # Customize the chart layout
# #   fig.update_layout(
# #     title='Probabilities for each class',
# #     xaxis_title='Probability',
# #     yaxis_title='Class',
# #     height=400,
# #     width=600,
# #     yaxis=dict(autorange="reversed")
# #   )
# 
# #   # Add value labels to the bars
# #   for i, prob in enumerate(sorted_probabilities):
# #       fig.add_annotation(
# #         x=prob,
# #         y=i,
# #         text=f'{prob:.4f}',
# #         showarrow=False,
# #         xanchor='left',
# #         xshift=5
# #   )
# 
# #   # Display the Plotly chart
# #   st.plotly_chart(fig)
# 
# 
# 
# #   saliency_map_path = f'saliency_maps/{uploaded_file.name}'
# #   explanation = generate_explanation(saliency_map_path, result, prediction[0][class_index])
# 
# #   st.write("## Explanation")
# #   st.write(explanation)
# 
# 
# 
# 
# 
# 
# 
# 
# 
# 
# 
# 
# 
# 
# 
# 
# 
# #  # Test
# # %%writefile app.py
# # import streamlit as st
# # import tensorflow as tf
# # from tensorflow.keras.models import load_model
# # from tensorflow.keras.preprocessing import image
# # import numpy as np
# # import plotly.graph_objects as go
# # import cv2
# # from tensorflow.keras.models import Sequential
# # from tensorflow.keras.layers import Dense, Dropout, Flatten
# # from tensorflow.keras.optimizers import Adamax
# # from tensorflow.keras.metrics import Precision, Recall
# # import google.generativeai as genai
# # from google.colab import userdata
# # import PIL.Image
# # import os
# # from dotenv import load_dotenv
# # load_dotenv()
# 
# # genai.configure(api_key=os.getenv("GOOGLE_API_KEY"))
# 
# # output_dir = 'saliency_maps'
# # os.makedirs(output_dir, exist_ok=True)
# 
# # # Function to generate the initial explanation based on prediction
# # def generate_explanation(img_path, model_prediction, confidence):
# #     prompt = f"""
# #     You are an expert neurologist interpreting a saliency map for a brain MRI scan, generated by a deep learning model trained to classify brain tumors into categories: glioma, meningioma, pituitary, or no tumor.
# 
# #     The model predicted the scan to be of class '{model_prediction}' with a confidence level of {confidence * 100}%.
# 
# #     Context for response:
# #     - Describe specific regions of the brain highlighted in light cyan where the model focused to arrive at this prediction.
# #       For example, reference specific lobes, sulci, or anatomical structures if they appear relevant.
# #     - Discuss how the highlighted regions correlate with typical tumor presentation of the predicted class. For instance,
# #       explain if the distribution, shape, or spread of these highlighted areas aligns with known patterns for {model_prediction}.
# #     - Provide insights into the reasoning process, considering the neural features that might influence the model's focus.
# #       For example, mention if it’s emphasizing regions of abnormal density, asymmetry, or unusual boundaries that are often seen in {model_prediction} cases.
# #     - Avoid generic statements, and aim to make each sentence contribute a unique insight into why the model likely made this prediction
# #       based on the observed highlights.
# #     - Maintain clarity and precision in describing the anatomical and functional relevance of the model’s focus points on the MRI scan.
# 
# #     Based on the above context, answer the following question from the user in a detailed yet concise manner.
# #     """
# #     img = PIL.Image.open(img_path)
# #     model = genai.GenerativeModel(model_name="gemini-1.5-flash")
# #     response = model.generate_content([prompt, img])
# #     return response.text
# 
# # # Function to generate chat responses based on user questions
# # def generate_neurology_chat_response(model, img, user_query, model_prediction, confidence):
# #     prompt = f"""
# #     You are an expert neurologist interpreting a saliency map for a brain MRI scan, generated by a deep learning model trained to classify brain tumors into categories: glioma, meningioma, pituitary, or no tumor.
# 
# #     The model has classified this MRI scan as '{model_prediction}' with a confidence level of {confidence * 100}%.
# 
# #     When responding, please:
# #     - Answer questions directly based on the provided MRI scan classification and the highlighted regions in the saliency map.
# #     - Focus on explaining why the model might have classified the tumor as {model_prediction}, including anatomical and structural details relevant to this tumor type.
# #     - Describe any relevant characteristics of the {model_prediction} tumor type, such as typical regions affected, common shapes, or patterns in MRI imaging.
# #     - Avoid disclaimers about being an AI and instead focus on providing educational information relevant to this classification.
# 
# #     Now, based on the model's classification and the saliency map, answer the following user question:
# 
# #     "{user_query}"
# #     """
# #     response = model.generate_content([prompt, img])
# #     return response.text
# 
# # def generate_saliency_map(model, img_array, class_index, img_size):
# #     with tf.GradientTape() as tape:
# #         img_tensor = tf.convert_to_tensor(img_array)
# #         tape.watch(img_tensor)
# #         predictions = model(img_tensor)
# #         target_class = predictions[:, class_index]
# 
# #     gradients = tape.gradient(target_class, img_tensor)
# #     gradients = tf.math.abs(gradients)
# #     gradients = tf.reduce_max(gradients, axis=-1)
# #     gradients = gradients.numpy().squeeze()
# 
# #     # Resize gradients to match original image size
# #     gradients = cv2.resize(gradients, img_size)
# 
# #     # Create a circular mask for the brain area
# #     center = (gradients.shape[0] // 2, gradients.shape[1] // 2)
# #     radius = min(center[0], center[1]) - 10
# #     y, x = np.ogrid[:gradients.shape[0], :gradients.shape[1]]
# #     mask = (x - center[0])**2 + (y - center[1])**2 <= radius**2
# 
# #     # Apply mask to gradients
# #     gradients = gradients * mask
# 
# #     # Normalize only the brain area
# #     brain_gradients = gradients[mask]
# #     if brain_gradients.max() > brain_gradients.min():
# #         brain_gradients = (brain_gradients - brain_gradients.min()) / (brain_gradients.max() - brain_gradients.min())
# #     gradients[mask] = brain_gradients
# 
# #     # Apply a higher threshold
# #     threshold = np.percentile(gradients[mask], 80)
# #     gradients[gradients < threshold] = 0
# 
# #     # Apply more aggressive smoothing
# #     gradients = cv2.GaussianBlur(gradients, (11, 11), 0)
# 
# #     # Create a heatmap overlay with enhanced contrast
# #     heatmap = cv2.applyColorMap(np.uint8(255 * gradients), cv2.COLORMAP_JET)
# #     heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)
# 
# #     # Resize heatmap to match original image size
# #     heatmap = cv2.resize(heatmap, img_size)
# #     # Superimpose the heatmap on original image with increased opacity
# #     original_img = image.img_to_array(img)
# #     superimposed_img = heatmap * 0.7 + original_img * 0.3
# #     superimposed_img = superimposed_img.astype(np.uint8)
# 
# #     img_path = os.path.join(output_dir, uploaded_file.name)
# #     with open(img_path, "wb") as f:
# #         f.write(uploaded_file.getbuffer())
# 
# #     saliency_map_path = f'saliency_maps/{uploaded_file.name}'
# 
# #     # Save the saliency map
# #     cv2.imwrite(saliency_map_path, cv2.cvtColor(superimposed_img, cv2.COLOR_RGB2BGR))
# 
# #     return superimposed_img
# 
# 
# 
# 
# # def load_xception_model(model_path):
# #     img_shape=(299,299,3)
# #     base_model = tf.keras.applications.Xception(include_top=False, weights="imagenet",
# #                                                 input_shape=img_shape, pooling='max')
# 
# #     model = Sequential([
# #         base_model,
# #         Flatten(),
# #         Dropout(rate=0.3),
# #         Dense(128, activation='relu'),
# #         Dropout(rate=0.25),
# #         Dense(4, activation='softmax')
# #     ])
# 
# #     model.build((None,) + img_shape)
# 
# #     # Compile the model
# #     model.compile(Adamax(learning_rate=0.001),
# #                   loss='categorical_crossentropy',
# #                   metrics=['accuracy',
# #                            Precision(),
# #                            Recall()])
# 
# #     model.load_weights(model_path)
# 
# #     return model
# 
# # # Main Streamlit app code
# # st.title("Brain Tumor Classification")
# # st.write("Upload an image of a brain MRI to classify the tumor type.")
# # uploaded_file = st.file_uploader("Choose an image...", type=["jpg", "jpeg", "png"])
# 
# # if uploaded_file is not None:
# #     selected_model = st.radio("Select Model", ("Transfer Learning - Xception", "Custom CNN"))
# 
# #     if selected_model == "Transfer Learning - Xception":
# #         model = load_xception_model('/content/xception_model.weights.h5')
# #         img_size = (299, 299)
# #     else:
# #         model = load_model('/content/cnn_model.h5')
# #         img_size = (224, 224)
# 
# #     labels = ['Glioma', 'Meningioma', 'No tumor', 'Pituitary']
# #     img = image.load_img(uploaded_file, target_size=img_size)
# #     img_array = image.img_to_array(img)
# #     img_array = np.expand_dims(img_array, axis=0) / 255.0
# 
# #     prediction = model.predict(img_array)
# #     class_index = np.argmax(prediction[0])
# #     result = labels[class_index]
# 
# #     st.write(f"Predicted Class: {result}")
# #     st.write("Predictions")
# #     for label, prob in zip(labels, prediction[0]):
# #         st.write(f"{label}: {prob:.4f}")
# 
# #     saliency_map = generate_saliency_map(model, img_array, class_index, img_size)
# #     col1, col2 = st.columns(2)
# #     with col1:
# #         st.image(uploaded_file, caption='Uploaded Image', use_column_width=True)
# #     with col2:
# #         st.image(saliency_map, caption='Saliency Map', use_column_width=True)
# 
# #     st.write("## Classification Results")
# #     # Display confidence and results (existing code for styled container)
# 
# #     # Explanation section
# #     saliency_map_path = f'saliency_maps/{uploaded_file.name}'
# #     explanation = generate_explanation(saliency_map_path, result, prediction[0][class_index])
# #     st.write("## Explanation")
# #     st.write(explanation)
# 
# #     # Chat with the MRI feature
# #     st.write("## Chat with the MRI Image")
# #     st.write("Ask questions about the MRI scan to the multimodal LLM.")
# #     user_query = st.text_input("Your question about the MRI scan:")
# 
# #     if user_query:
# #         response_text = generate_neurology_chat_response(
# #             model=genai.GenerativeModel(model_name="gemini-1.5-flash"),
# #             img=img,
# #             user_query=user_query,
# #             model_prediction=result,
# #             confidence=prediction[0][class_index]
# #         )
# #         st.write("### Model's Response:")
# #         st.write(response_text)
# 
# 
# 
# 
# 
# 
# 
# 
# 
# # Test 3
# %%writefile app.py
# import streamlit as st
# import tensorflow as tf
# from tensorflow.keras.models import load_model
# from tensorflow.keras.preprocessing import image
# import numpy as np
# import plotly.graph_objects as go
# import cv2
# from tensorflow.keras.models import Sequential
# from tensorflow.keras.layers import Dense, Dropout, Flatten
# from tensorflow.keras.optimizers import Adamax
# from tensorflow.keras.metrics import Precision, Recall
# import google.generativeai as genai
# import PIL.Image
# import os
# from dotenv import load_dotenv
# load_dotenv()
# 
# genai.configure(api_key=os.getenv("GOOGLE_API_KEY"))
# 
# output_dir = 'saliency_maps'
# os.makedirs(output_dir, exist_ok=True)
# 
# # Function to generate the initial explanation based on prediction
# def generate_explanation(img_path, model_prediction, confidence):
#     prompt = f"""
#     You are an expert neurologist interpreting a saliency map for a brain MRI scan, generated by a deep learning model trained to classify brain tumors into categories: glioma, meningioma, pituitary, or no tumor.
# 
#     The model predicted the scan to be of class '{model_prediction}' with a confidence level of {confidence * 100}%.
# 
#     Context for response:
#     - Describe specific regions of the brain highlighted in light cyan where the model focused to arrive at this prediction.
#       For example, reference specific lobes, sulci, or anatomical structures if they appear relevant.
#     - Discuss how the highlighted regions correlate with typical tumor presentation of the predicted class. For instance,
#       explain if the distribution, shape, or spread of these highlighted areas aligns with known patterns for {model_prediction}.
#     - Provide insights into the reasoning process, considering the neural features that might influence the model's focus.
#       For example, mention if it’s emphasizing regions of abnormal density, asymmetry, or unusual boundaries that are often seen in {model_prediction} cases.
#     - Avoid generic statements, and aim to make each sentence contribute a unique insight into why the model likely made this prediction
#       based on the observed highlights.
#     - Maintain clarity and precision in describing the anatomical and functional relevance of the model’s focus points on the MRI scan.
# 
#     Based on the above context, answer the following question from the user in a detailed yet concise manner.
#     """
#     img = PIL.Image.open(img_path)
#     model = genai.GenerativeModel(model_name="gemini-1.5-flash")
#     response = model.generate_content([prompt, img])
#     return response.text
# 
# # Function to generate chat responses based on user questions
# def generate_neurology_chat_response(model, img, user_query, model_prediction, confidence):
#     prompt = f"""
#     You are an expert neurologist interpreting a saliency map for a brain MRI scan, generated by a deep learning model trained to classify brain tumors into categories: glioma, meningioma, pituitary, or no tumor.
# 
#     The model has classified this MRI scan as '{model_prediction}' with a confidence level of {confidence * 100}%.
# 
#     When responding, please:
#     - Answer questions directly based on the provided MRI scan classification and the highlighted regions in the saliency map.
#     - Focus on explaining why the model might have classified the tumor as {model_prediction}, including anatomical and structural details relevant to this tumor type.
#     - Describe any relevant characteristics of the {model_prediction} tumor type, such as typical regions affected, common shapes, or patterns in MRI imaging.
#     - Avoid disclaimers about being an AI and instead focus on providing educational information relevant to this classification.
# 
#     Now, based on the model's classification and the saliency map, answer the following user question:
# 
#     "{user_query}"
#     """
#     response = model.generate_content([prompt, img])
#     return response.text
# 
# def generate_saliency_map(model, img, img_array, class_index, img_size, uploaded_file):
#     with tf.GradientTape() as tape:
#         img_tensor = tf.convert_to_tensor(img_array)
#         tape.watch(img_tensor)
#         predictions = model(img_tensor)
#         target_class = predictions[:, class_index]
# 
#     gradients = tape.gradient(target_class, img_tensor)
#     gradients = tf.math.abs(gradients)
#     gradients = tf.reduce_max(gradients, axis=-1)
#     gradients = gradients.numpy().squeeze()
# 
#     # Resize gradients to match original image size
#     gradients = cv2.resize(gradients, img_size)
# 
#     # Create a circular mask for the brain area
#     center = (gradients.shape[0] // 2, gradients.shape[1] // 2)
#     radius = min(center[0], center[1]) - 10
#     y, x = np.ogrid[:gradients.shape[0], :gradients.shape[1]]
#     mask = (x - center[0])**2 + (y - center[1])**2 <= radius**2
# 
#     # Apply mask to gradients
#     gradients = gradients * mask
# 
#     # Normalize only the brain area
#     brain_gradients = gradients[mask]
#     if brain_gradients.max() > brain_gradients.min():
#         brain_gradients = (brain_gradients - brain_gradients.min()) / (brain_gradients.max() - brain_gradients.min())
#     gradients[mask] = brain_gradients
# 
#     # Apply a higher threshold
#     threshold = np.percentile(gradients[mask], 80)
#     gradients[gradients < threshold] = 0
# 
#     # Apply more aggressive smoothing
#     gradients = cv2.GaussianBlur(gradients, (11, 11), 0)
# 
#     # Create a heatmap overlay with enhanced contrast
#     heatmap = cv2.applyColorMap(np.uint8(255 * gradients), cv2.COLORMAP_JET)
#     heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)
# 
#     # Resize heatmap to match original image size
#     heatmap = cv2.resize(heatmap, img_size)
#     # Superimpose the heatmap on original image with increased opacity
#     original_img = image.img_to_array(img)
#     superimposed_img = heatmap * 0.7 + original_img * 0.3
#     superimposed_img = superimposed_img.astype(np.uint8)
# 
#     img_path = os.path.join(output_dir, uploaded_file.name)
#     with open(img_path, "wb") as f:
#         f.write(uploaded_file.getbuffer())
# 
#     saliency_map_path = f'saliency_maps/{uploaded_file.name}'
# 
#     # Save the saliency map
#     cv2.imwrite(saliency_map_path, cv2.cvtColor(superimposed_img, cv2.COLOR_RGB2BGR))
# 
#     return superimposed_img
# 
# 
# def load_xception_model(model_path):
#     img_shape=(299,299,3)
#     base_model = tf.keras.applications.Xception(include_top=False, weights="imagenet",
#                                                 input_shape=img_shape, pooling='max')
# 
#     model = Sequential([
#         base_model,
#         Flatten(),
#         Dropout(rate=0.3),
#         Dense(128, activation='relu'),
#         Dropout(rate=0.25),
#         Dense(4, activation='softmax')
#     ])
# 
#     model.build((None,) + img_shape)
# 
#     # Compile the model
#     model.compile(Adamax(learning_rate=0.001),
#                   loss='categorical_crossentropy',
#                   metrics=['accuracy',
#                            Precision(),
#                            Recall()])
# 
#     model.load_weights(model_path)
# 
#     return model
# 
# # Main Streamlit app with tabbed layout
# st.title("Brain Tumor Classification")
# 
# # Tabs for different features
# tabs = st.tabs(["Single Prediction", "Model Comparison"])
# 
# # Common functionality for each tab
# def display_tab_content(tab_key):
#     st.write("Upload an image of a brain MRI to classify the tumor type.")
#     uploaded_file = st.file_uploader("Choose an image...", type=["jpg", "jpeg", "png"], key=tab_key)
# 
#     if uploaded_file is not None:
#         selected_model = st.radio("Select Model", ("Transfer Learning - Xception", "Custom CNN"), key=f"{tab_key}_model")
# 
#         if selected_model == "Transfer Learning - Xception":
#             model = load_xception_model('/content/xception_model.weights.h5')
#             img_size = (299, 299)
#         else:
#             model = load_model('/content/cnn_model.h5')
#             img_size = (224, 224)
# 
#         labels = ['Glioma', 'Meningioma', 'No tumor', 'Pituitary']
#         img = image.load_img(uploaded_file, target_size=img_size)
#         img_array = image.img_to_array(img)
#         img_array = np.expand_dims(img_array, axis=0) / 255.0
# 
#         prediction = model.predict(img_array)
#         class_index = np.argmax(prediction[0])
#         result = labels[class_index]
# 
#         st.write(f"Predicted Class: {result}")
#         st.write("Predictions")
#         for label, prob in zip(labels, prediction[0]):
#             st.write(f"{label}: {prob:.4f}")
# 
#         # Saliency map
#         saliency_map = generate_saliency_map(model, img, img_array, class_index, img_size, uploaded_file)
#         col1, col2 = st.columns(2)
#         with col1:
#             st.image(uploaded_file, caption='Uploaded Image', use_column_width=True)
#         with col2:
#             st.image(saliency_map, caption='Saliency Map', use_column_width=True)
# 
#         # Explanation
#         saliency_map_path = f'saliency_maps/{uploaded_file.name}'
#         explanation = generate_explanation(saliency_map_path, result, prediction[0][class_index])
#         st.write("### Explanation")
#         st.write(explanation)
# 
#         # Chat with the MRI feature
#         st.write("### Chat with the MRI Image")
#         st.write("Ask questions about the MRI scan to the multimodal LLM.")
#         user_query = st.text_input("Your question about the MRI scan:", key=f"{tab_key}_query")
# 
#         if user_query:
#             response_text = generate_neurology_chat_response(
#                 model=genai.GenerativeModel(model_name="gemini-1.5-flash"),
#                 img=img,
#                 user_query=user_query,
#                 model_prediction=result,
#                 confidence=prediction[0][class_index]
#             )
#             st.write("### Model's Response:")
#             st.write(response_text)
# 
# # Single Prediction Tab
# with tabs[0]:
#     display_tab_content("single_prediction")
# 
# # Model Comparison Tab
# with tabs[1]:
#     display_tab_content("model_comparison")
#

thread = Thread(target=run_streamlit)
thread.start()

public_url = ngrok.connect(addr='8501', proto='http', bind_tls=True)

print("Public URL:", public_url)

tunnels = ngrok.get_tunnels()
for tunnel in tunnels:
  print(f"Closing tunnel: {tunnel.public_url} -> {tunnel.config['addr']}")
  ngrok.disconnect(tunnel.public_url)

